name: EasyShop Application Deployment

on:
  workflow_dispatch:
  repository_dispatch:
    types: [deploy-applications]
  workflow_run:
    workflows: ["Terraform Infrastructure Provisioning"]
    types: [completed]
    branches: [main]

env:
  REGISTRY: ${{ secrets.TF_ACR_NAME }}.azurecr.io
  IMAGE_NAME: easyshop
  AKS_CLUSTER_NAME: ${{ secrets.TF_AKS_CLUSTER_NAME }}
  RESOURCE_GROUP: ${{ secrets.TF_PROJECT_NAME }}-rg
  NAMESPACE: easyshop

jobs:
  deploy-application:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' || github.event_name == 'repository_dispatch' || (github.event_name == 'workflow_run' && github.event.workflow_run.conclusion == 'success') }}
    
    steps:
    - name: 🚀 Checkout Repository
      uses: actions/checkout@v4

    - name: 🔐 Azure Login
      uses: azure/login@v2
      with:
        creds: |
          {
            "clientId": "${{ secrets.ARM_CLIENT_ID }}",
            "clientSecret": "${{ secrets.ARM_CLIENT_SECRET }}",
            "subscriptionId": "${{ secrets.ARM_SUBSCRIPTION_ID }}",
            "tenantId": "${{ secrets.ARM_TENANT_ID }}"
          }

    - name: 🎯 Generate SHA Version
      id: version
      run: |
        VERSION="${GITHUB_SHA::8}"
        echo "VERSION=$VERSION" >> $GITHUB_ENV
        echo "📦 Using SHA version: $VERSION"

    # ✅ FIXED: Set up Docker Buildx with container driver that supports cache
    - name: 🐋 Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      with:
        driver: docker-container
        driver-opts: |
          image=moby/buildkit:latest
        use: true

    # ✅ FIXED: Use Azure CLI for ACR login (more reliable than docker-login action)
    - name: 🔑 Login to ACR
      run: |
        az acr login --name ${{ secrets.TF_ACR_NAME }}

    # ✅ FIXED: Build and Push with ACR registry cache (more reliable than GHA cache for ACR)
    # Modify your existing build step to capture the digest:
    # Modify your existing build step to capture the digest:
    - name: 🏗️ Build and Push with Caching
      id: build
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        platforms: linux/amd64
        tags: |
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.VERSION }}
          ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
        build-args: |
          GIT_SHA=${{ env.VERSION }}
          BUILD_DATE=${{ github.event.head_commit.timestamp }}
        cache-from: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:cache
        cache-to: type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:cache,mode=max
        outputs: type=image,name=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }},push=true

    # Then extract the digest from the build output:
    - name: 📌 Get Image Digest from Build
      run: |
        # The build step outputs metadata including the digest
        IMAGE_DIGEST="${{ steps.build.outputs.digest }}"
        
        if [[ -n "$IMAGE_DIGEST" ]]; then
          IMAGE_WITH_DIGEST="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}@${IMAGE_DIGEST}"
          echo "✅ Got digest from build: $IMAGE_DIGEST"
        else
          # Fallback: extract from build metadata
          IMAGE_WITH_DIGEST="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.VERSION }}"
          echo "⚠️ No digest from build, using tag: $IMAGE_WITH_DIGEST"
        fi
        
        echo "IMAGE_WITH_DIGEST=$IMAGE_WITH_DIGEST" >> $GITHUB_ENV
        echo "📌 Final image: $IMAGE_WITH_DIGEST"

    - name: ⚙️ Connect to AKS & Install Kustomize
      run: |
        echo "🔑 Getting AKS credentials..."
        az aks get-credentials \
          --resource-group ${{ env.RESOURCE_GROUP }} \
          --name ${{ env.AKS_CLUSTER_NAME }} \
          --overwrite-existing
        
        echo "📦 Installing kustomize..."
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash
        sudo mv kustomize /usr/local/bin/

    - name: 🚀 Blue-Green Deployment
      run: |
        set -e
        
        echo "🚀 Starting Blue-Green Deployment with Enhanced Debugging..."
        
        kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -
        
        cd kubernetes
        
        # ==========================================
        # PHASE 1: FILE VALIDATION (SKIP NON-K8s FILES)
        # ==========================================
        echo "📋 Phase 1: Validating Kubernetes resource files..."
        failed_files=()
        
        # Files to SKIP - these are NOT Kubernetes resources
        skip_files=("kustomization.yaml" "00-kind-config.yaml")
        
        for file in *.yaml *.yml; do
          if [[ -f "$file" ]]; then
            # Check if this file should be skipped
            skip=false
            for skip_file in "${skip_files[@]}"; do
              if [[ "$file" == "$skip_file" ]]; then
                skip=true
                echo "  Skipping $file (not a K8s resource)"
                break
              fi
            done
            
            # Only validate actual Kubernetes resources
            if [[ "$skip" == false ]]; then
              echo -n "  Testing $file... "
              if kubectl --dry-run=client apply -f "$file" &>/tmp/file-test.log; then
                echo "✅"
              else
                echo "❌"
                failed_files+=("$file")
                echo "    Error in $file:"
                head -3 /tmp/file-test.log | sed 's/^/      /'
              fi
            fi
          fi
        done
        
        if [[ ${#failed_files[@]} -gt 0 ]]; then
          echo "🚨 FAILED FILES: ${failed_files[*]}"
          echo "❌ Cannot proceed with invalid YAML files!"
          exit 1
        fi
        
        echo "✅ All Kubernetes resource files are valid"
        
        # ==========================================
        # PHASE 2: KUSTOMIZATION BUILD TEST
        # ==========================================
        echo ""
        echo "📝 Phase 2: Testing kustomization build..."
        
        # Update image
        echo "📝 Updating image to: ${{ env.IMAGE_WITH_DIGEST }}"
        kustomize edit set image gibranf/easyshop=${{ env.IMAGE_WITH_DIGEST }}
        
        # Test kustomize build
        if ! kustomize build . > /tmp/build-output.yaml 2>/tmp/build-error.log; then
          echo "❌ Kustomize build failed!"
          echo "Error details:"
          cat /tmp/build-error.log
          exit 1
        fi
        
        # Count resources
        resource_count=$(grep -c "^kind:" /tmp/build-output.yaml 2>/dev/null || echo "0")
        echo "📊 Generated $resource_count resources"
        
        if [[ $resource_count -eq 0 ]]; then
          echo "❌ No resources generated!"
          echo "Build output:"
          head -50 /tmp/build-output.yaml
          exit 1
        fi
        
        echo "✅ Kustomize build successful!"
        
        # ==========================================
        # PHASE 3: DEPLOYMENT
        # ==========================================
        echo ""
        echo "🚀 Phase 3: Executing deployment..."
        
        # Determine target deployment
        CURRENT=$(kubectl get svc easyshop-service -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.selector.app}' 2>/dev/null || echo "easyshop-blue")
        
        if [[ "$CURRENT" == "easyshop-blue" ]]; then
          TARGET="easyshop-green"
          echo "🔄 Switching to GREEN"
        else
          TARGET="easyshop-blue"  
          echo "🔄 Switching to BLUE"
        fi
        
        # Apply manifests
        echo "📦 Applying $resource_count resources..."
        kustomize build . | kubectl apply -f -
        
        # Wait for deployment
        echo "⏳ Waiting for $TARGET to be ready..."
        kubectl rollout status deployment/$TARGET -n ${{ env.NAMESPACE }} --timeout=300s
        
        # Switch traffic
        echo "🔀 Switching service to $TARGET..."
        kubectl patch svc easyshop-service -n ${{ env.NAMESPACE }} -p '{"spec":{"selector":{"app":"'$TARGET'"}}}'
        
        # Scale down old deployment
        if [[ "$CURRENT" != "$TARGET" ]]; then
          echo "📉 Scaling down $CURRENT..."
          kubectl scale deployment/$CURRENT --replicas=0 -n ${{ env.NAMESPACE }}
        fi
        
        echo ""
        echo "✅ BLUE-GREEN DEPLOYMENT COMPLETED!"
        echo "🎯 Active deployment: $TARGET"
        echo "📊 Resources deployed: $resource_count"

    - name: 🔍 Verify Deployment
      run: |
        echo "🔍 Verifying deployment..."
        
        # Check pods
        echo "📦 Pods in ${{ env.NAMESPACE }}:"
        kubectl get pods -n ${{ env.NAMESPACE }}
        
        # Check services
        echo "🌐 Services in ${{ env.NAMESPACE }}:"
        kubectl get svc -n ${{ env.NAMESPACE }}
        
        # Get the actual hostname from ingress
        echo "🔗 Ingress in ${{ env.NAMESPACE }}:"
        kubectl get ingress -n ${{ env.NAMESPACE }}
        
        INGRESS_HOST=$(kubectl get ingress easyshop-ingress -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.rules[0].host}' 2>/dev/null || echo "${{ secrets.TF_DNS_ZONE_NAME }}")
        echo "INGRESS_HOST=$INGRESS_HOST" >> $GITHUB_ENV

    - name: 📋 Deployment Summary
      run: |
        echo "🎉 Blue-Green Deployment Complete!"
        echo "=================================="
        echo "🏷️  SHA Version: ${{ env.VERSION }}"
        echo "🐋 Image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ env.VERSION }}"
        echo "📌 Digest: ${{ env.IMAGE_WITH_DIGEST }}"
        echo "🎯 Cluster: ${{ env.AKS_CLUSTER_NAME }}"
        echo "🏠 Namespace: ${{ env.NAMESPACE }}"
        echo "🌐 URL: https://${{ env.INGRESS_HOST }}"
        echo "📍 Commit: ${{ github.sha }}"
        echo ""
        echo "🔄 Blue-Green Strategy:"
        echo "  ✅ Deployed to inactive slot with digest pinning"
        echo "  ✅ Verified health and readiness probes"
        echo "  ✅ Switched traffic with zero downtime"
        echo "  ✅ Scaled down old deployment"
        echo "=================================="